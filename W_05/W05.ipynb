{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pymorphy2\n",
    "import datetime\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://lenta.ru/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "findheaders = re.compile('<h1.+?>(.+)</h1>', re.S)\n",
    "boa = re.compile('div class=\"b-text clearfix js-topic__text\" itemprop=\"articleBody\"><p>', re.S)\n",
    "eoa = re.compile('<div class=\"b-box\"><i>', re.S)\n",
    "delscript = re.compile('<script.+?>(.+)</script>', re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLentaArticle2(url):\n",
    "    article = requests.get(url)\n",
    "    title = findheaders.findall(article.text)[0]\n",
    "    text = eoa.split( boa.split(article.text)[1] )\n",
    "    text = \"\".join(delscript.split(text[0]))\n",
    "    return BeautifulSoup ( title + '\\n--------\\n' + text, 'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLentaArticle(url):\n",
    "    article = requests.get(url)\n",
    "    title = findheaders.findall(article.text)[0]\n",
    "    \n",
    "    bs = BeautifulSoup ( article.text, 'lxml')\n",
    "    #title = str(bs('h1'))\n",
    "    text = delscript.split( str(bs('p'))[1:-1])\n",
    "    return BeautifulSoup ( title + '\\n--------\\n' + \"\".join(text), 'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путин отдохнул в тайге и уехал к морю\n",
      "--------\n",
      "Президент России Владимир Путин провел субботу, 29 сентября, в тайге. Об этом сообщил пресс-секретарь главы государства Дмитрий Песков, передает РИА Новости., «По дороге из Душанбе Владимир Путин совершил остановку в Хакасии, где провел субботний день в тайге с кратким отдыхом», — рассказал он и добавил, что после этого президент отправился в Сочи., Путин прибыл в столицу Таджикистана для участия в саммите в пятницу, 28 сентября. Там российский лидер, в частности, пообщался с президентом Киргизии Сооронбаем Жээнбековым  и главой Таджикистана Эмомали Рахмоном., В процессе церемонии подписания документов Путин зачитался «Евгением Онегиным». «Сначала Путин положил книгу чуть слева от себя, но, поставив несколько подписей, взял экземпляр стихотворного романа Александра Пушкина и пролистал несколько страниц. Принесли новую порцию документов, президент поставил свою подпись и снова открыл книгу», — писало об этом РИА Новости., В 2017 году Путин заночевал в сибирской тайге. После рабочего визита в Красноярск он побывал в походных условиях., \n"
     ]
    }
   ],
   "source": [
    "art_text = getLentaArticle('https://lenta.ru/news/2018/09/30/tayga/')\n",
    "print ( art_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "posConv = {'ADJF':'_ADJ', 'NOUN':'_NOUN', 'VERB':'_VERB'}\n",
    "meaningfullPoSes = ['ADJF', 'NOUN', 'VERB']\n",
    "\n",
    "def getArticleDictionary( text, needPos = None):\n",
    "    words = [a[0] for a in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "    reswords = []\n",
    "    \n",
    "    for w in words:\n",
    "        wordform = morph.parse(w)[0]\n",
    "        if wordform.tag.POS in meaningfullPoSes:\n",
    "            if needPos != None:\n",
    "                reswords.append(wordform.normal_form + posConv[wordform.tag.POS] )\n",
    "            else:\n",
    "                reswords.append(wordform.normal_form)\n",
    "    return Counter ( reswords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'путин_NOUN': 7, 'тайга_NOUN': 4, 'президент_NOUN': 4, 'владимир_NOUN': 2, 'провести_VERB': 2, 'сентябрь_NOUN': 2, 'риа_NOUN': 2, 'новость_NOUN': 2, 'таджикистан_NOUN': 2, 'документ_NOUN': 2, 'книга_NOUN': 2, 'подпись_NOUN': 2, 'отдохнуть_VERB': 1, 'уехать_VERB': 1, 'море_NOUN': 1, 'россия_NOUN': 1, 'суббота_NOUN': 1, 'сообщить_VERB': 1, 'пресс-секретарь_NOUN': 1, 'глава_NOUN': 1, 'государство_NOUN': 1, 'дмитрий_NOUN': 1, 'песок_NOUN': 1, 'передавать_VERB': 1, 'дорога_NOUN': 1, 'душанбе_NOUN': 1, 'совершить_VERB': 1, 'остановка_NOUN': 1, 'хакасия_NOUN': 1, 'субботний_ADJ': 1, 'день_NOUN': 1, 'краткий_ADJ': 1, 'отдых_NOUN': 1, 'рассказать_VERB': 1, 'добавить_VERB': 1, 'отправиться_VERB': 1, 'сочи_NOUN': 1, 'прибыть_VERB': 1, 'столица_NOUN': 1, 'участие_NOUN': 1, 'саммит_NOUN': 1, 'пятница_NOUN': 1, 'российский_ADJ': 1, 'лидер_NOUN': 1, 'частность_NOUN': 1, 'пообщаться_VERB': 1, 'киргизия_NOUN': 1, 'сооронбай_NOUN': 1, 'жээнбеков_NOUN': 1, 'главый_ADJ': 1, 'эмомали_NOUN': 1, 'рахмон_NOUN': 1, 'процесс_NOUN': 1, 'церемония_NOUN': 1, 'подписание_NOUN': 1, 'зачитаться_VERB': 1, 'евгений_NOUN': 1, 'онегин_NOUN': 1, 'положить_VERB': 1, 'взять_VERB': 1, 'экземпляр_NOUN': 1, 'стихотворный_ADJ': 1, 'роман_NOUN': 1, 'александр_NOUN': 1, 'пушкин_NOUN': 1, 'пролистать_VERB': 1, 'страница_NOUN': 1, 'принести_VERB': 1, 'новый_ADJ': 1, 'порция_NOUN': 1, 'поставить_VERB': 1, 'свой_ADJ': 1, 'открыть_VERB': 1, 'писать_VERB': 1, 'год_NOUN': 1, 'заночевать_VERB': 1, 'сибирский_ADJ': 1, 'рабочий_NOUN': 1, 'визит_NOUN': 1, 'красноярск_NOUN': 1, 'побывать_VERB': 1, 'походный_ADJ': 1, 'условие_NOUN': 1})\n"
     ]
    }
   ],
   "source": [
    "stat1 = getArticleDictionary( art_text, True )\n",
    "print ( statl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017', '28', '29', 'александра', 'взял', 'визита', 'владимир', 'где', 'главой', 'главы', 'году', 'государства', 'день', 'для', 'дмитрий', 'добавил', 'документов', 'дороге', 'душанбе', 'евгением', 'жээнбековым', 'заночевал', 'зачитался', 'из', 'киргизии', 'книгу', 'красноярск', 'кратким', 'лидер', 'морю', 'несколько', 'но', 'новости', 'новую', 'об', 'он', 'онегиным', 'остановку', 'от', 'отдохнул', 'отдыхом', 'открыл', 'отправился', 'передает', 'песков', 'писало', 'по', 'побывал', 'подписания', 'подписей', 'подпись', 'положил', 'пообщался', 'порцию', 'после', 'поставив', 'поставил', 'походных', 'президент', 'президентом', 'пресс', 'прибыл', 'принесли', 'провел', 'пролистал', 'процессе', 'путин', 'пушкина', 'пятницу', 'рабочего', 'рассказал', 'рахмоном', 'риа', 'романа', 'россии', 'российский', 'саммите', 'свою', 'себя', 'секретарь', 'сентября', 'сибирской', 'слева', 'сначала', 'снова', 'совершил', 'сообщил', 'сооронбаем', 'сочи', 'стихотворного', 'столицу', 'страниц', 'субботний', 'субботу', 'таджикистана', 'тайге', 'там', 'уехал', 'условиях', 'участия', 'хакасии', 'церемонии', 'частности', 'что', 'чуть', 'экземпляр', 'эмомали', 'этого', 'этом']\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "counter = CountVectorizer()\n",
    "res = counter.fit_transform( [art_text] )\n",
    "print(counter.get_feature_names() )\n",
    "print(counter.vocabulary_.get('путин'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['путин', 'отдохнул', 'тайге', 'уехал', 'морю', 'президент', 'россии', 'владимир', 'путин', 'провел', 'субботу', '29', 'сентября', 'тайге', 'об', 'этом', 'сообщил', 'пресс', 'секретарь', 'главы', 'государства', 'дмитрий', 'песков', 'передает', 'риа', 'новости', 'по', 'дороге', 'из', 'душанбе', 'владимир', 'путин', 'совершил', 'остановку', 'хакасии', 'где', 'провел', 'субботний', 'день', 'тайге', 'кратким', 'отдыхом', 'рассказал', 'он', 'добавил', 'что', 'после', 'этого', 'президент', 'отправился', 'сочи', 'путин', 'прибыл', 'столицу', 'таджикистана', 'для', 'участия', 'саммите', 'пятницу', '28', 'сентября', 'там', 'российский', 'лидер', 'частности', 'пообщался', 'президентом', 'киргизии', 'сооронбаем', 'жээнбековым', 'главой', 'таджикистана', 'эмомали', 'рахмоном', 'процессе', 'церемонии', 'подписания', 'документов', 'путин', 'зачитался', 'евгением', 'онегиным', 'сначала', 'путин', 'положил', 'книгу', 'чуть', 'слева', 'от', 'себя', 'но', 'поставив', 'несколько', 'подписей', 'взял', 'экземпляр', 'стихотворного', 'романа', 'александра', 'пушкина', 'пролистал', 'несколько', 'страниц', 'принесли', 'новую', 'порцию', 'документов', 'президент', 'поставил', 'свою', 'подпись', 'снова', 'открыл', 'книгу', 'писало', 'об', 'этом', 'риа', 'новости', '2017', 'году', 'путин', 'заночевал', 'сибирской', 'тайге', 'после', 'рабочего', 'визита', 'красноярск', 'он', 'побывал', 'походных', 'условиях', 'путин отдохнул', 'отдохнул тайге', 'тайге уехал', 'уехал морю', 'морю президент', 'президент россии', 'россии владимир', 'владимир путин', 'путин провел', 'провел субботу', 'субботу 29', '29 сентября', 'сентября тайге', 'тайге об', 'об этом', 'этом сообщил', 'сообщил пресс', 'пресс секретарь', 'секретарь главы', 'главы государства', 'государства дмитрий', 'дмитрий песков', 'песков передает', 'передает риа', 'риа новости', 'новости по', 'по дороге', 'дороге из', 'из душанбе', 'душанбе владимир', 'владимир путин', 'путин совершил', 'совершил остановку', 'остановку хакасии', 'хакасии где', 'где провел', 'провел субботний', 'субботний день', 'день тайге', 'тайге кратким', 'кратким отдыхом', 'отдыхом рассказал', 'рассказал он', 'он добавил', 'добавил что', 'что после', 'после этого', 'этого президент', 'президент отправился', 'отправился сочи', 'сочи путин', 'путин прибыл', 'прибыл столицу', 'столицу таджикистана', 'таджикистана для', 'для участия', 'участия саммите', 'саммите пятницу', 'пятницу 28', '28 сентября', 'сентября там', 'там российский', 'российский лидер', 'лидер частности', 'частности пообщался', 'пообщался президентом', 'президентом киргизии', 'киргизии сооронбаем', 'сооронбаем жээнбековым', 'жээнбековым главой', 'главой таджикистана', 'таджикистана эмомали', 'эмомали рахмоном', 'рахмоном процессе', 'процессе церемонии', 'церемонии подписания', 'подписания документов', 'документов путин', 'путин зачитался', 'зачитался евгением', 'евгением онегиным', 'онегиным сначала', 'сначала путин', 'путин положил', 'положил книгу', 'книгу чуть', 'чуть слева', 'слева от', 'от себя', 'себя но', 'но поставив', 'поставив несколько', 'несколько подписей', 'подписей взял', 'взял экземпляр', 'экземпляр стихотворного', 'стихотворного романа', 'романа александра', 'александра пушкина', 'пушкина пролистал', 'пролистал несколько', 'несколько страниц', 'страниц принесли', 'принесли новую', 'новую порцию', 'порцию документов', 'документов президент', 'президент поставил', 'поставил свою', 'свою подпись', 'подпись снова', 'снова открыл', 'открыл книгу', 'книгу писало', 'писало об', 'об этом', 'этом риа', 'риа новости', 'новости 2017', '2017 году', 'году путин', 'путин заночевал', 'заночевал сибирской', 'сибирской тайге', 'тайге после', 'после рабочего', 'рабочего визита', 'визита красноярск', 'красноярск он', 'он побывал', 'побывал походных', 'походных условиях']\n",
      "['2017', '28', '29', 'александра', 'взял', 'визита', 'владимир', 'где', 'главой', 'главы', 'году', 'государства', 'день', 'для', 'дмитрий', 'добавил', 'документов', 'дороге', 'душанбе', 'евгением', 'жээнбековым', 'заночевал', 'зачитался', 'из', 'киргизии', 'книгу', 'красноярск', 'кратким', 'лидер', 'морю', 'несколько', 'но', 'новости', 'новую', 'об', 'он', 'онегиным', 'остановку', 'от', 'отдохнул', 'отдыхом', 'открыл', 'отправился', 'передает', 'песков', 'писало', 'по', 'побывал', 'подписания', 'подписей', 'подпись', 'положил', 'пообщался', 'порцию', 'после', 'поставив', 'поставил', 'походных', 'президент', 'президентом', 'пресс', 'прибыл', 'принесли', 'провел', 'пролистал', 'процессе', 'путин', 'пушкина', 'пятницу', 'рабочего', 'рассказал', 'рахмоном', 'риа', 'романа', 'россии', 'российский', 'саммите', 'свою', 'себя', 'секретарь', 'сентября', 'сибирской', 'слева', 'сначала', 'снова', 'совершил', 'сообщил', 'сооронбаем', 'сочи', 'стихотворного', 'столицу', 'страниц', 'субботний', 'субботу', 'таджикистана', 'тайге', 'там', 'уехал', 'условиях', 'участия', 'хакасии', 'церемонии', 'частности', 'что', 'чуть', 'экземпляр', 'эмомали', 'этого', 'этом']\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "counter12 = CountVectorizer(ngram_range=(1,2))\n",
    "analyse = counter12.build_analyzer()\n",
    "print( analyse(art_text) )\n",
    "res= counter12.fit_transform( [art_text] )\n",
    "print(counter.get_feature_names() )\n",
    "print(counter.vocabulary_.get('путин'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeaningfullWords(text):\n",
    "    words=[]\n",
    "    tokens=re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', text)\n",
    "    for t in tokens:\n",
    "        pv = morph.parse(t)\n",
    "        for p in pv:\n",
    "            if p.tag.POS in meaningfullPoSes:\n",
    "                words.append(p.normal_form)\n",
    "                break\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'путин': 7, 'век': 14, 'тайга': 4, 'исполняющий': 5, 'президент': 4, 'владимир': 2, 'провести': 2, 'сентябрь': 2, 'этот': 3, 'риа': 2, 'новость': 2, 'секунда': 2, 'посол': 2, 'таджикистан': 2, 'документ': 2, 'книга': 2, 'подпись': 2, 'век тайга': 3, 'владимир путин': 2, 'риа новость': 2}\n",
      "---\n",
      "{'путин': 7, 'в': 14, 'тайга': 4, 'и': 5, 'президент': 4, 'владимир': 2, 'провести': 2, 'сентябрь': 2, 'о': 2, 'это': 3, 'риа': 2, 'новость': 2, 'с': 2, 'он': 2, 'после': 2, 'таджикистан': 2, 'документ': 2, 'книга': 2, 'поставить': 2, 'несколько': 2, 'подпись': 2, 'в тайга': 3, 'владимир путин': 2, 'о это': 2, 'риа новость': 2}\n"
     ]
    }
   ],
   "source": [
    "c=[' '.join(getMeaningfullWords(art_text))]\n",
    "c2=[' '.join([morph.parse(r)[0].normal_form for r in re.findall('[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+', art_text)])]\n",
    "\n",
    "lemmaCounter=CountVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "\n",
    "analyze = lemmaCounter.build_analyzer()\n",
    "res1=analyze(c[0])\n",
    "res2=lemmaCounter.fit_transform(c)\n",
    "print({w:res2[0][0,lemmaCounter.vocabulary_[w]] for w in lemmaCounter.vocabulary_ if res2[0][0,lemmaCounter.vocabulary_[w]]>1})\n",
    "print(\"---\")\n",
    "res1=analyze(c2[0])\n",
    "res2=lemmaCounter.fit_transform(c2)\n",
    "print({w:res2[0][0,lemmaCounter.vocabulary_[w]] for w in lemmaCounter.vocabulary_ if res2[0][0,lemmaCounter.vocabulary_[w]]>1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(a, b):\n",
    "    if len(a.keys())==0 or len(b.keys())==0:\n",
    "        return 0\n",
    "    sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "    suma2=sum([a[na]*a[na] for na in a.keys()])\n",
    "    sumb2=sum([b[nb]*b[nb] for nb in b.keys()])\n",
    "    return sumab/math.sqrt(suma2*sumb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009597211839133202\n",
      "0.051216617822002236\n",
      "0.12321187388436787\n",
      "0.10845193904480363\n",
      "0.08038418992031009\n"
     ]
    }
   ],
   "source": [
    "stat2=getArticleDictionary(getLentaArticle(\"https://lenta.ru/news/2018/02/15/pengilly_domoi/\"), True)\n",
    "stat3=getArticleDictionary(getLentaArticle(\"https://lenta.ru/news/2018/02/15/tar_mor/\"), True)\n",
    "stat4=getArticleDictionary(getLentaArticle(\"https://lenta.ru/news/2018/02/15/olympmovies/\"), True)\n",
    "\n",
    "print(cosineSimilarity(stat1, stat2))\n",
    "print(cosineSimilarity(stat1, stat3))\n",
    "print(cosineSimilarity(stat2, stat3))\n",
    "print(cosineSimilarity(stat2, stat4))\n",
    "print(cosineSimilarity(stat3, stat4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getNewsPaper:\n",
    "    articles=[]     # Загруженные статьи.\n",
    "    dictionaries=[] # Посчитанные словари (векторное представление статей).\n",
    "        \n",
    "    # Конструктор - компилирует регулярные выражения и загружает морфологию.\n",
    "    def __init__(self):\n",
    "        self.delscript = re.compile(\"<script.*?>.+?</script>\", re.S)\n",
    "        self.findheaders = re.compile(\"<h1.+?>(.+)</h1>\", re.S)\n",
    "        self.boa = re.compile('<div class=\"b-text clearfix js-topic__text\" itemprop=\"articleBody\">', re.S)\n",
    "        self.eoa = re.compile('<div class=\"b-box\">\\s*?<i>', re.S)\n",
    "        self.findURLs = re.compile('<h3>(.+?)</h3>', re.S)\n",
    "        self.rboa = re.compile('<p class=\"MegaArticleBody_first-p_2htdt\">', re.S)\n",
    "        self.reoa = re.compile('<div class=\"Attribution_container_28wm1\">', re.S)\n",
    "        self.rfindURLs = re.compile('''<div class=\"headlineMed\"><a href='(.+?)'>''', re.S)\n",
    "        # Создаем и загружаем морфологический словарь.\n",
    "        self.morph=pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    # Загрузка статьи по URL.\n",
    "    def getLentaArticle(self, url):\n",
    "        \"\"\" getLentaArticle gets the body of an article from Lenta.ru\"\"\"\n",
    "        # Получает текст страницы.\n",
    "        art=requests.get(url)\n",
    "        # Находим заголовок.\n",
    "        title = findheaders.findall(art.text)[0]\n",
    "        # Выделяем текст новости.\n",
    "        bs=BeautifulSoup(art.text, \"lxml\")\n",
    "        # Выкусываем скрипты - BeautifulSoup не справляетсяя с ними. bs['p'] выделяет параграфы текста.\n",
    "        # [1:-1] применяется ля того, чтобы выкусить квадратные скобки, которые добавляются здесь при преобразовании к строке.\n",
    "        text=delscript.split(str(bs('p'))[1:-1])\n",
    "        # Выкусываем остальные теги.\n",
    "        self.articles.append(BeautifulSoup(title+\"\\n-----\\n\"+\" \".join(text), \"lxml\").get_text())\n",
    "\n",
    "    # Загрузка всех статей за один день.\n",
    "    def getLentaDay(self, url):\n",
    "        \"\"\" Gets all URLs for a given day and gets all texts. \"\"\"\n",
    "        try:\n",
    "            day = requests.get(url) # Грузим страницу со списком всех статей.\n",
    "            cand = self.findURLs.findall(day.text) # Выделяем адреса статей.\n",
    "            links = ['https://lenta.ru'+re.findall('\"(.+?)\"', x)[0] for x in cand]\n",
    "            for l in links: # Загружаем статьи.\n",
    "                self.getLentaArticle(l)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Загрузка всех статей за несколько дней.\n",
    "    def getLentaPeriod(self, start, finish):\n",
    "        curdate=start\n",
    "        while curdate<=finish:\n",
    "            print(curdate.strftime('%Y/%m/%d')) # Just in case.\n",
    "            # Список статей грузится с вот такого адреса.\n",
    "            res=self.getLentaDay('https://lenta.ru/news/'+curdate.strftime('%Y/%m/%d'))\n",
    "            curdate+=datetime.timedelta(days=1)\n",
    "      \n",
    "    # Потроение вектора для статьи.\n",
    "    posConv={'ADJF':'_ADJ','NOUN':'_NOUN','VERB':'_VERB'}\n",
    "    def getArticleDictionary(self, text, needPos=None):\n",
    "        words=[a[0] for a in re.findall(\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text)]\n",
    "        reswords=[]\n",
    "    \n",
    "        for w in words:\n",
    "            wordform=self.morph.parse(w)[0]\n",
    "            try:\n",
    "                if wordform.tag.POS in ['ADJF', 'NOUN', 'VERB']:\n",
    "                    if needPos!=None:\n",
    "                        reswords.append(wordform.normal_form+self.posConv[wordform.tag.POS])\n",
    "                    else:\n",
    "                        reswords.append(wordform.normal_form)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        stat=Counter(reswords)\n",
    "#        stat={a: stat[a] for a in stat.keys() if stat[a]>1}\n",
    "        return stat\n",
    "\n",
    "    # Посчитаем вектора для всех статей.\n",
    "    def calcArticleDictionaries(self, needPos=None):\n",
    "        self.dictionaries=[]\n",
    "        for a in self.articles:\n",
    "            self.dictionaries.append(self.getArticleDictionary(a, needPos))\n",
    "\n",
    "    # Сохраняем стстьи в файл.\n",
    "    def saveArticles(self, filename):\n",
    "        \"\"\" Saves all articles to a file with a filename. \"\"\"\n",
    "        newsfile=open(filename, \"w\")\n",
    "        for art in self.articles:\n",
    "            newsfile.write('\\n=====\\n'+art)\n",
    "        newsfile.close()\n",
    "\n",
    "    # Читаем статьи из файла.\n",
    "    def loadArticles(self, filename):\n",
    "        \"\"\" Loads and replaces all articles from a file with a filename. \"\"\"\n",
    "        newsfile=open(filename, encoding=\"utf-8\")\n",
    "        text=newsfile.read()\n",
    "        self.articles=text.split('\\n=====\\n')[1:]\n",
    "#        self.articles=[a.replace('\\xa0', ' ') for a in text.split('\\n=====\\n')[1:]]\n",
    "        newsfile.close()\n",
    "\n",
    "    # Для удобства - поиск статьи по ее заголовку.\n",
    "    def findNewsByTitle(self, title):\n",
    "        for i, a in enumerate(self.articles):\n",
    "            if title==a.split('\\n-----\\n')[0]:\n",
    "                return i\n",
    "        return -1\n",
    "\n",
    "def cosineSimilarity(a, b):\n",
    "    if len(a.keys())==0 or len(b.keys())==0:\n",
    "        return 0\n",
    "    sumab=sum([a[na]*b[na] for na in a.keys() if na in b.keys()])\n",
    "    suma2=sum([a[na]*a[na] for na in a.keys()])\n",
    "    sumb2=sum([b[nb]*b[nb] for nb in b.keys()])\n",
    "    return sumab/math.sqrt(suma2*sumb2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка статей за заданный период.\n",
    "# !!! Это рабоатет довольно долго, пользуйтесь сохраненными данными!!!\n",
    "lenta=getNewsPaper()\n",
    "# lenta.getLentaPeriod(datetime.date(2018, 2, 1), datetime.date(2018, 2, 14))\n",
    "# lenta.saveArticles(\"lenta2018.txt\")\n",
    "lenta.loadArticles(\"data\\lenta2018.txt\")\n",
    "lenta.calcArticleDictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Раскрыто происхождение новейшей украинской крылатой ракеты\n",
      "Россия поставила Украине оружие «сдерживания агрессора»\n",
      "0.6522716186492549 516\n"
     ]
    }
   ],
   "source": [
    "i1 = 0\n",
    "maxCos, maxpos = -1, -1\n",
    "for i in range(len(lenta.articles)):\n",
    "    if i != i1:\n",
    "        c = cosineSimilarity(lenta.dictionaries[i1], lenta.dictionaries[i])\n",
    "        if c>maxCos:\n",
    "            maxCos, maxpos = c, i\n",
    "print(lenta.articles[i1].split('\\n-----\\n')[0])\n",
    "print(lenta.articles[maxpos].split('\\n-----\\n')[0])\n",
    "print(maxCos, maxpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "likesport=['Власти США обвинили МОК и ФИФА в коррупции', 'Пробирки WADA для допинг-проб оказались бракованными', 'Пожизненно отстраненных российских спортсменов оправдали', 'В Кремле порадовались за оправданных российских спортсменов', 'Россия вернется на первое место Олимпиады-2014', 'МОК разочаровало оправдание российских олимпийцев', 'Мутко загрустил после оправдания российских спортсменов', 'Оправданный призер Сочи-2014 призвал «добить ситуацию» с МОК', 'Путин предостерег от эйфории после оправдания российских олимпийцев', 'Родченков не смог вразумительно ответить на вопросы суда', 'Оправданный россиянин позлорадствовал над делившими медали Игр-2014 иностранцами', 'В CAS отказались считать оправданных россиян невиновными', 'Адвокат Родченкова заговорил о смерти чистого спорта после оправдания россиян', 'Американская скелетонистка сочла россиян ушедшими от законного наказания']\n",
    "likeelect=['Социологи подсчитали планирующих проголосовать на выборах-2018', 'Собчак пообещала дать Трампу пару советов', 'На выборы президента России пойдут почти 80 процентов избирателей', 'Песков вспомнил предупреждение и отказался комментировать поездку Собчак в США', 'Собчак съездила на завтрак с Трампом и разочаровалась', 'Грудинин уступил в популярности КПРФ', 'Собчак потребовала признать незаконной регистрацию Путина на выборах', 'У Грудинина обнаружили два не до конца закрытых счета в Швейцарии и Австрии', 'Грудинин раскрыл историю происхождения дома в Испании', 'Путина зарегистрировали кандидатом в президенты', 'В Кремле отреагировали на слухи о голосовании Путина в Севастополе', 'Коммунистов вновь обвинили в незаконной агитации за Грудинина', 'ЦИК выявила обман со стороны Грудинина', 'Грудинин ответил на претензии ЦИК', 'Жириновский захотел сбросить ядерную бомбу на резиденцию Порошенко']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sporttext=' '.join([lenta.articles[lenta.findNewsByTitle(art)] for art in likesport])\n",
    "sportdict=lenta.getArticleDictionary(sporttext)\n",
    "electtext=' '.join([lenta.articles[lenta.findNewsByTitle(art)] for art in likeelect])\n",
    "electdict=lenta.getArticleDictionary(electtext)\n",
    "#print(sportdict)\n",
    "#print(electdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Пожизненно отстраненных российских спортсменов оправдали', 'В Кремле порадовались за оправданных российских спортсменов', 'Россия вернется на первое место Олимпиады-2014', 'МОК разочаровало оправдание российских олимпийцев', 'Мутко загрустил после оправдания российских спортсменов', 'Олимпиада в Пхенчхане побила рекорд по презервативам', 'Оправданный призер Сочи-2014 призвал «добить ситуацию» с МОК', 'Путин предостерег от эйфории после оправдания российских олимпийцев', 'Родченков не смог вразумительно ответить на вопросы суда', 'Оправданный россиянин позлорадствовал над делившими медали Игр-2014 иностранцами', 'В CAS отказались считать оправданных россиян невиновными', 'Адвокат Родченкова заговорил о смерти чистого спорта после оправдания россиян', 'Американская скелетонистка сочла россиян ушедшими от законного наказания', 'Глава USADA почуял вонь российской атаки на чистый спорт', 'После оправдания российских спортсменов Макларена назвали идиотом', 'МОК посчитал оправдание российских спортсменов «торжеством обманщиков и воров»', 'Федерацию бобслея России обвинили в нежелании пускать спортсменов на Олимпиаду', 'Названы условия продолжения борьбы МОК против россиян', 'Четырехкратный олимпийский чемпион встал на сторону россиян и пристыдил МОК', 'МОК подумает над приглашением на Олимпиаду оправданных россиян', 'Оправданным россиянам запретили участвовать в Олимпиаде', 'МОК обозначил сроки по решению о допуске оправданных россиян на Олимпиаду', 'В секретной базе найдены сотни аномальных допинг-проб', 'Назван знаменосец россиян на открытии Олимпиады', 'Комиссия МОК отказалась пустить на Олимпиаду оправданных CAS россиян', 'WADA сорвало тренировку сборной России по хоккею в Пхенчхане', 'Глава МОК рассказал о процедуре допуска оправданных россиян на Олимпиаду', 'Песков прокомментировал отказ МОК пустить на Олимпиаду оправданных россиян', 'Шесть российских сборных отказались от участия в церемонии открытия Олимпиады', 'МОК сделает из россиян пример нетерпимости к допингу', 'Лыжники присоединились к отказавшимся от церемонии открытия Олимпиады россиянам', 'Медведев пристыдил МОК', 'Президент МОК объяснил нежелание приглашать на Игры оправданных россиян', 'Немцы порадовались решению не пускать оправданных россиян на Олимпиаду', 'МОК уличил очередных российских спортсменов в употреблении допинга', 'Российские спортсмены продолжили борьбу с МОК', 'Раскрыты условия снятия запрета на российский флаг на Олимпиаде', 'Россиянам спрогнозировали девять медалей на Олимпиаде-2018', 'В Европе нашлась новая допинг-система', 'Серебряный призер Сочи пригрозила сунуть медаль между булок желающим ее забрать', 'Российские спортсмены пропустят Олимпиаду из-за затянувшегося суда', 'Американскую спортсменку разозлило оправдание российских олимпийцев', 'Названы условия появления российского флага на закрытии Игр', 'Немецкий биатлонист сравнил оправдание российских олимпийцев с плевком в лицо', 'Хакеры раскрыли канадский заговор против российского спорта', 'Российские керлингисты уступили сборной США в дебютной игре Олимпиады-2018', 'Российские олимпийцы пожаловались на слежку со стороны иностранной прессы', 'Российские олимпийцы подверглись дискриминации со стороны канадцев', 'CAS отказался рассматривать апелляции отстраненных от Олимпиады россиян', 'Российские болельщики осадили штаб-квартиру WADA', 'Потерявший шансы попасть на Олимпиаду Кулижников прокомментировал решение CAS', 'Бренды и чиновники отказались от индивидуальности ради российских спортсменов', 'Трехкратная чемпионка мира выступила против наказания невиновных россиян', 'Российские олимпийцы смогут носить шапку с триколором', 'Отстраненные россияне лишились последнего шанса поехать на Олимпиаду', 'WADA возрадовалось решению CAS о недопуске россиян к Олимпиаде', 'МОК поддержал решение не допустить российских спортсменов на Олимпиаду', 'Адвокат Родченкова поблагодарил бога за недопуск россиян на Олимпиаду', 'Мутко назвал причины недопуска россиян на Олимпиаду', 'Кремль прокомментировал решение CAS о недопуске россиян к Олимпиаде', 'В Госдуме пообещали разобраться с главой МОК после Олимпиады', 'Бах обещал распустить CAS в случае оправдания российских атлетов', 'CAS объяснил решение о недопуске россиян на Олимпиаду', 'Елистратов посвятил медаль «подло и мерзко отстраненным» россиянам', 'Спортсменка из США обрадовалась отсутствию лидеров сборной России на Олимпиаде', 'Российских спортсменов посчитали самыми стильными на Олимпиаде', 'Попавшегося на допинге француза спугнули вопросом о Викторе Ане', 'Олимпийский чемпион окрестил российских биатлонисток «кем попало»', 'МОК предупредил российских атлетов о неожиданных допинг-тестах на Олимпиаде', 'Выигравший золото биатлонист выступил против недопуска Шипулина к Олимпиаде', 'Российский олимпиец рассказал о нежелании американцев жать ему руку', 'Родченков поведал о природе греха', 'Песков отверг обвинения Родченкова и указал на его психический недуг', 'Фуркад выиграл Олимпиаду и раскритиковал решение не допускать до нее россиян', 'МОК захотел наказать россиянина за посвящение медали отстраненным олимпийцам', 'Сдан первый положительный допинг-тест на Олимпиаде', 'Керлингисты принесли России третью медаль Олимпиады', 'Елена Вяльбе предположила вербовку Родченкова в Канаде', 'Два российских спортсмена пропустили Олимпиаду из-за ошибки МОК', 'МОК объяснил отсутствие двух россиян в списке приглашенных на Олимпиаду', 'Ошибочно не допущенный к Олимпиаде россиянин обиделся на МОК', 'Овечкин поблагодарил НХЛ за просмотр олимпийского хоккея по телевизору', 'Президент МОК предстал пред ликом российских олимпийцев']\n",
      "['Социологи подсчитали планирующих проголосовать на выборах-2018', 'У Грудинина обнаружили два не до конца закрытых счета в Швейцарии и Австрии', 'Грудинин раскрыл историю происхождения дома в Испании', 'Путина зарегистрировали кандидатом в президенты', 'В Кремле отреагировали на слухи о голосовании Путина в Севастополе', 'На выборы президента России пойдут почти 80 процентов избирателей', 'Песков вспомнил предупреждение и отказался комментировать поездку Собчак в США', 'Собчак съездила на завтрак с Трампом и разочаровалась', 'Коммунистов вновь обвинили в незаконной агитации за Грудинина', 'Грудинин ответил на претензии ЦИК', 'Грудинин уступил в популярности КПРФ', 'Собчак потребовала признать незаконной регистрацию Путина на выборах']\n"
     ]
    }
   ],
   "source": [
    "thrs=0.4\n",
    "thre=0.5\n",
    "cosess=[lenta.articles[i].split('\\n-----\\n')[0] for i in range(len(lenta.dictionaries)) if cosineSimilarity(sportdict, lenta.dictionaries[i])>thrs]\n",
    "print(cosess)\n",
    "cosese=[lenta.articles[i].split('\\n-----\\n')[0] for i in range(len(lenta.dictionaries)) if cosineSimilarity(electdict, lenta.dictionaries[i])>thre]\n",
    "print(cosese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_new=getNewsPaper()\n",
    "#lenta_new.getLentaPeriod(datetime.date(2018, 2, 15), datetime.date(2018, 2, 15))\n",
    "#lenta_new.saveArticles(\"lenta20180215.txt\")\n",
    "lenta_new.loadArticles(\"data\\lenta20180215.txt\")\n",
    "lenta_new.calcArticleDictionaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Российский сноубордист сломал ногу на Олимпиаде', 'Российскую лыжницу затравили на Олимпиаде']\n",
      "['Кремль опроверг информацию о засекречивании данных по россиянам в Сирии', 'Порошенко раскрыл детали разговора с Путиным', 'Грудинин оговорился о финансовых махинациях', 'Прогнозируемую явку на выборах президента сочли высокой']\n"
     ]
    }
   ],
   "source": [
    "thrs_new = 0.3\n",
    "thre_new = 0.3\n",
    "cosess_new = [lenta_new.articles[i].split('\\n-----\\n')[0] for i in range(len(lenta_new.dictionaries)) if cosineSimilarity(sportdict, lenta_new.dictionaries[i])>thrs_new]\n",
    "print(cosess_new)\n",
    "cosese_new = [lenta_new.articles[i].split('\\n-----\\n')[0] for i in range(len(lenta_new.dictionaries)) if cosineSimilarity(electdict, lenta_new.dictionaries[i])>thre_new]\n",
    "print(cosese_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[' '.join(getMeaningfullWords(n)) for n in lenta.articles]\n",
    "\n",
    "tfCounter=TfidfVectorizer(ngram_range=(1,2), token_pattern=r'[А-Яа-яЁё]+\\-[А-Яа-яЁё]+|[А-Яа-яЁё]+')\n",
    "\n",
    "analyze = tfCounter.build_analyzer()\n",
    "res=tfCounter.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ближний': 0.09754172040483444, 'восток': 0.10389546512876865, 'платформа': 0.11428148479237515, 'жозе': 0.16535511285226273, 'увеличение': 0.0842033272150634, 'возможность': 0.08574845736217529, 'доставка': 0.13234427079429065, 'клиентский': 0.1744831264097395, 'сервис': 0.0709906385519639, 'услуга': 0.06742359087070612, 'ближний восток': 0.13825073355807999, 'клиентский сервис': 0.11632208427315967}\n"
     ]
    }
   ],
   "source": [
    "id_article=6\n",
    "\n",
    "res2=analyze(lenta.articles[id_article])\n",
    "tfs=list(set(res[id_article][0, tfCounter.vocabulary_.get(k)] for k in res2 if k in tfCounter.vocabulary_.keys()))\n",
    "tfs2=[k for k in tfs if k>np.average(tfs)]\n",
    "#tfs2=[k for k in tfs if k>np.average(tfs)+np.std(tfs)]\n",
    "print({w:res[id_article][0, tfCounter.vocabulary_[w]] for w in res2 if w in tfCounter.vocabulary_.keys() and res[id_article][0, tfCounter.vocabulary_[w]] in tfs2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Импортируем библиотеки Word2Vec\n",
    "from gensim.models.word2vec import Word2Vec # Собственно модель.\n",
    "from gensim.models.word2vec import LineSentence # Выравнивание текста по предложениям.\n",
    "from gensim.models import KeyedVectors # Семантические вектора.\n",
    "# На самом деле, нам потребуется только последняя.\n",
    "import numpy as np # Вектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('data/news_upos_cbow_600_2_2018.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.58170e-02,  4.41830e-02, -1.71040e-02, -4.57520e-02,\n",
       "        2.04150e-02, -2.40040e-02,  4.09340e-02,  3.11130e-02,\n",
       "       -3.95260e-02,  2.20970e-02,  2.24920e-02,  1.92750e-02,\n",
       "        2.78080e-02,  4.49070e-02,  5.63220e-02,  4.45900e-03,\n",
       "        4.61480e-02,  3.07340e-02, -6.30660e-02,  7.29010e-02,\n",
       "        7.12300e-03, -1.71800e-02,  1.96740e-02,  2.98010e-02,\n",
       "        2.71750e-02,  8.77070e-02, -1.97520e-02,  3.35100e-03,\n",
       "       -7.84200e-03,  8.84600e-03, -3.89400e-02,  1.03100e-02,\n",
       "        2.48070e-02, -4.09000e-03, -1.73660e-02, -7.46190e-02,\n",
       "        1.10265e-01,  2.89020e-02, -5.00060e-02,  4.90970e-02,\n",
       "       -4.85360e-02,  3.00110e-02,  3.67230e-02,  3.55780e-02,\n",
       "       -7.86430e-02, -6.60400e-03, -1.02970e-02, -4.44200e-03,\n",
       "        6.34600e-02,  1.40280e-02, -6.75700e-03, -1.19300e-03,\n",
       "       -4.25510e-02, -2.17790e-02,  7.87590e-02, -8.13890e-02,\n",
       "        1.08440e-02, -3.11530e-02,  6.01860e-02,  8.62800e-03,\n",
       "       -3.41890e-02, -3.25180e-02, -1.70000e-05, -1.41150e-02,\n",
       "        1.73410e-02, -9.52600e-03, -3.00990e-02,  3.60800e-03,\n",
       "       -1.35400e-03, -1.75680e-02,  9.36840e-02, -1.08760e-02,\n",
       "       -3.34870e-02, -1.20010e-02,  4.74330e-02, -4.18050e-02,\n",
       "       -5.19660e-02, -2.94000e-03,  2.37610e-02,  1.08780e-02,\n",
       "       -4.16700e-03, -4.29070e-02, -1.17470e-02,  9.58170e-02,\n",
       "       -1.57330e-02, -1.33200e-03, -2.07420e-02, -6.58800e-02,\n",
       "       -6.41800e-03, -4.52930e-02, -8.29900e-02,  1.44790e-02,\n",
       "       -4.15200e-02,  4.83450e-02,  2.59800e-02, -1.67610e-02,\n",
       "       -3.13500e-03,  2.45070e-02, -1.71440e-02,  7.58690e-02,\n",
       "        4.66510e-02, -1.37280e-02,  4.07540e-02, -6.54870e-02,\n",
       "        3.53170e-02, -1.16056e-01, -1.63280e-02,  1.12310e-02,\n",
       "       -4.75370e-02,  3.39860e-02,  2.32730e-02,  2.04850e-02,\n",
       "       -9.86700e-03,  8.14900e-03, -1.49680e-02, -1.30900e-02,\n",
       "        6.34940e-02,  2.50890e-02, -1.75700e-02, -1.41550e-02,\n",
       "        6.57600e-03, -3.51100e-03, -1.50240e-02, -6.86350e-02,\n",
       "        3.87710e-02, -4.04240e-02,  4.87410e-02,  3.28610e-02,\n",
       "        3.73690e-02,  4.56050e-02, -4.24890e-02,  4.81180e-02,\n",
       "       -6.02150e-02,  4.68340e-02,  7.32800e-03,  1.35280e-02,\n",
       "        1.77010e-02,  4.51730e-02,  2.67290e-02, -2.48840e-02,\n",
       "       -1.84450e-02,  8.54200e-03,  7.07670e-02,  1.15040e-02,\n",
       "        2.12360e-02,  2.25880e-02, -1.30540e-02,  1.21020e-02,\n",
       "       -2.37520e-02,  2.83630e-02, -2.95440e-02, -2.55350e-02,\n",
       "       -1.32010e-02, -9.95080e-02, -5.55790e-02, -1.53130e-02,\n",
       "       -1.78810e-02, -3.21110e-02,  8.63800e-03, -3.72650e-02,\n",
       "        7.13640e-02,  2.54150e-02,  1.90820e-02, -2.20270e-02,\n",
       "        2.26500e-02, -1.08470e-02, -2.80670e-02, -8.32760e-02,\n",
       "       -6.16300e-03,  3.41230e-02, -2.82690e-02,  1.51130e-02,\n",
       "       -7.12770e-02, -8.28600e-03, -7.94500e-03,  4.53990e-02,\n",
       "       -5.35430e-02,  3.45140e-02,  2.12990e-02,  2.41770e-02,\n",
       "       -4.06100e-02,  3.61000e-03,  1.68350e-02, -5.37560e-02,\n",
       "        2.25300e-03, -9.41560e-02,  2.73830e-02,  7.19860e-02,\n",
       "        3.09090e-02,  3.51460e-02, -5.48850e-02,  1.25850e-02,\n",
       "       -2.83930e-02,  2.20100e-02,  9.68100e-02, -1.75020e-02,\n",
       "        1.91070e-02,  2.93300e-03, -5.59340e-02, -3.91300e-03,\n",
       "       -5.71670e-02, -4.01560e-02,  3.64740e-02,  2.18130e-02,\n",
       "       -5.78630e-02, -1.65990e-02, -7.15700e-03, -1.89100e-03,\n",
       "        9.34700e-03,  9.34500e-03,  1.05100e-03,  2.13830e-02,\n",
       "       -1.36690e-02,  3.34710e-02,  1.08416e-01,  8.64080e-02,\n",
       "        1.27240e-02, -3.43210e-02, -2.44370e-02, -1.22360e-02,\n",
       "       -7.09840e-02, -4.45500e-02,  2.23850e-02, -7.42710e-02,\n",
       "        2.75940e-02, -1.30060e-02, -4.41500e-02, -3.20340e-02,\n",
       "        4.74700e-02,  4.21120e-02,  2.92230e-02, -2.17230e-02,\n",
       "        1.29000e-03,  3.60000e-03, -2.86540e-02, -2.46990e-02,\n",
       "       -1.04320e-02, -4.56330e-02,  5.04290e-02, -7.40500e-03,\n",
       "        2.87440e-02,  4.83580e-02, -3.58590e-02,  1.28850e-02,\n",
       "        2.16310e-02,  1.41140e-02,  2.13500e-02,  4.61940e-02,\n",
       "        1.06110e-02, -2.65690e-02, -7.18720e-02, -6.56220e-02,\n",
       "       -5.68850e-02, -5.40370e-02,  9.93200e-03,  4.97730e-02,\n",
       "        4.18600e-03,  3.25990e-02, -1.84620e-02,  1.18360e-02,\n",
       "        3.00100e-02,  4.60780e-02,  3.05790e-02, -4.33680e-02,\n",
       "        1.70130e-02,  5.42770e-02, -4.99000e-03,  8.58400e-03,\n",
       "        4.50780e-02,  2.77350e-02,  2.47000e-04,  3.30190e-02,\n",
       "       -5.08170e-02,  3.36540e-02, -4.88600e-03, -2.22050e-02,\n",
       "       -1.33320e-02, -9.84180e-02,  4.29860e-02,  3.00210e-02,\n",
       "       -1.61450e-02, -2.54840e-02,  1.29220e-02,  4.68040e-02,\n",
       "       -8.52600e-03, -4.56170e-02, -2.81730e-02, -6.12600e-03,\n",
       "       -4.65360e-02, -2.54400e-02, -3.64710e-02,  2.12860e-02,\n",
       "        3.84840e-02, -7.88600e-03, -6.96900e-03,  1.04101e-01,\n",
       "        4.49750e-02,  7.56810e-02,  3.07300e-02,  5.22300e-03,\n",
       "        6.47350e-02,  5.63310e-02,  2.08590e-02,  3.41500e-03,\n",
       "        3.26670e-02,  2.59000e-04, -1.69130e-02,  1.00710e-02,\n",
       "        3.32370e-02,  3.53620e-02,  2.24520e-02, -1.28050e-02,\n",
       "        6.23300e-03, -3.25350e-02, -2.74280e-02, -1.06836e-01,\n",
       "        6.42590e-02,  6.15140e-02, -3.34010e-02,  1.56390e-02,\n",
       "        4.95410e-02, -5.76220e-02,  4.80460e-02,  2.43700e-02,\n",
       "       -7.66300e-02, -1.75820e-02,  1.56650e-02, -7.05700e-03,\n",
       "       -3.42160e-02,  6.51130e-02,  2.35170e-02, -5.34200e-03,\n",
       "       -3.01970e-02,  6.43130e-02,  2.94320e-02,  4.03020e-02,\n",
       "        1.48890e-02, -9.91100e-03,  2.35490e-02, -3.47570e-02,\n",
       "        1.95940e-02, -2.53800e-02,  8.14820e-02, -1.63970e-02,\n",
       "        6.86980e-02, -1.46080e-01,  3.95640e-02, -8.02930e-02,\n",
       "        8.77930e-02,  1.72000e-03, -4.20480e-02, -2.78100e-03,\n",
       "        4.91980e-02,  1.80930e-02,  1.03260e-02, -2.80770e-02,\n",
       "        2.88760e-02, -1.04220e-02, -3.46790e-02,  4.77600e-02,\n",
       "        5.63280e-02, -7.55160e-02, -2.30150e-02,  8.10000e-04,\n",
       "        7.23360e-02,  1.87910e-02, -5.41900e-03,  3.43920e-02,\n",
       "       -4.77850e-02,  3.84600e-02,  1.77490e-02,  9.49870e-02,\n",
       "        4.30740e-02,  8.10610e-02,  6.17700e-03,  1.81340e-02,\n",
       "        1.86280e-02,  3.12870e-02, -4.71210e-02, -3.45790e-02,\n",
       "       -1.47330e-02,  2.89200e-02, -1.66580e-02,  2.63720e-02,\n",
       "        1.86380e-02,  2.81680e-02,  4.56890e-02, -4.87750e-02,\n",
       "        1.25820e-02, -1.76190e-02, -1.14620e-02, -2.23310e-02,\n",
       "       -1.80930e-02,  6.22680e-02, -1.47850e-02,  2.79330e-02,\n",
       "       -4.52110e-02, -7.32700e-03,  3.97900e-03, -7.42900e-03,\n",
       "        6.32700e-02, -3.37400e-03,  8.30190e-02,  2.04030e-02,\n",
       "        7.55300e-03,  1.52640e-02,  1.66170e-02,  1.64630e-02,\n",
       "       -8.08200e-03, -1.37930e-02,  2.30700e-02,  8.01590e-02,\n",
       "       -2.37580e-02,  9.86600e-03, -1.41559e-01, -2.43380e-02,\n",
       "        2.49730e-02,  5.35740e-02, -3.38900e-02, -6.01780e-02,\n",
       "        1.24110e-02, -4.00900e-03, -2.62980e-02, -2.08420e-02,\n",
       "       -1.21100e-03, -1.39000e-03, -5.46400e-03, -3.57420e-02,\n",
       "       -2.32210e-02, -5.80900e-02, -2.10910e-02, -2.48620e-02,\n",
       "       -3.60280e-02,  6.11670e-02,  2.81610e-02, -6.78300e-03,\n",
       "       -2.30140e-02,  2.63510e-02, -1.51910e-02, -1.07750e-02,\n",
       "        2.64700e-02,  1.15950e-02, -2.28150e-02, -7.54500e-03,\n",
       "       -4.46410e-02,  8.14640e-02,  4.45780e-02,  5.68040e-02,\n",
       "        1.30470e-02,  1.64230e-02, -2.07980e-02, -6.72620e-02,\n",
       "       -3.34460e-02, -1.10480e-02,  4.34630e-02,  2.74840e-02,\n",
       "        4.87170e-02, -7.49010e-02,  2.93730e-02, -2.75730e-02,\n",
       "        1.67410e-02,  1.73000e-04, -1.24190e-02,  3.30330e-02,\n",
       "       -3.21150e-02, -1.89760e-02,  3.38530e-02, -4.52900e-02,\n",
       "        5.06350e-02, -1.38870e-02,  2.01890e-02, -5.04090e-02,\n",
       "        3.96440e-02,  6.23700e-03,  6.26200e-03,  4.83750e-02,\n",
       "       -2.96980e-02, -4.19900e-03, -3.31680e-02,  4.18800e-03,\n",
       "        2.80770e-02,  8.71580e-02,  6.09290e-02, -1.39000e-02,\n",
       "        3.72060e-02, -4.26600e-02,  8.85000e-03, -8.13000e-03,\n",
       "        2.00250e-02,  2.16000e-04,  4.31200e-02,  2.51050e-02,\n",
       "        2.44200e-02,  2.42490e-02, -2.56670e-02,  2.87740e-02,\n",
       "        1.47040e-02,  1.70220e-02, -3.69800e-02, -4.80440e-02,\n",
       "       -4.70820e-02,  2.61950e-02,  1.09490e-02,  2.35640e-02,\n",
       "       -8.47400e-03,  2.12940e-02, -5.63700e-02, -2.77010e-02,\n",
       "        8.66870e-02, -4.20710e-02, -7.31800e-03, -2.83700e-02,\n",
       "        9.08170e-02, -3.50300e-03, -9.03340e-02, -1.24024e-01,\n",
       "        1.28010e-02,  3.17560e-02,  7.34290e-02, -6.35410e-02,\n",
       "       -5.12300e-03,  6.53300e-03,  6.40500e-03,  5.06020e-02,\n",
       "        6.50780e-02,  1.55510e-02,  2.94990e-02,  3.19600e-03,\n",
       "        2.43200e-02, -2.02710e-02, -6.62100e-03, -1.82230e-02,\n",
       "        3.49420e-02,  1.92320e-02,  6.81510e-02,  1.04680e-02,\n",
       "       -9.16760e-02,  2.35420e-02, -9.37700e-03, -7.82830e-02,\n",
       "       -2.52680e-02,  3.52310e-02,  4.43870e-02, -3.16630e-02,\n",
       "       -2.57130e-02,  6.81300e-03,  5.83200e-03, -2.58550e-02,\n",
       "       -2.30000e-05, -4.86850e-02,  1.24510e-02, -2.55640e-02,\n",
       "        4.05050e-02, -6.44700e-03,  6.24040e-02,  1.25082e-01,\n",
       "        4.96450e-02, -5.06990e-02, -7.87900e-03, -4.27150e-02,\n",
       "        1.83360e-02,  2.50940e-02, -2.15260e-02,  6.80240e-02,\n",
       "        7.90890e-02, -1.80300e-02,  5.00650e-02,  3.52410e-02,\n",
       "       -5.49990e-02, -1.97230e-02,  2.57900e-02, -7.60670e-02,\n",
       "       -2.80590e-02,  4.93530e-02,  2.02760e-02, -5.81830e-02,\n",
       "       -6.55810e-02, -4.25300e-02,  5.96230e-02,  2.51050e-02,\n",
       "       -3.75890e-02, -2.16270e-02, -1.30130e-02, -1.24520e-02,\n",
       "        4.16160e-02,  2.84330e-02, -2.38660e-02,  3.83800e-03,\n",
       "       -6.61500e-03, -1.96510e-02, -3.45180e-02, -8.18200e-03,\n",
       "       -3.03560e-02, -4.10120e-02, -4.88180e-02, -9.28080e-02,\n",
       "       -7.40000e-04, -6.02940e-02,  5.28500e-03, -6.04880e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['огонь_NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('императрица_NOUN', 0.54018235206604),\n",
       " ('государь_NOUN', 0.4910103678703308),\n",
       " ('царь_NOUN', 0.4542006850242615),\n",
       " ('самодержец_NOUN', 0.415338397026062),\n",
       " ('елизавета::петровна_PROPN', 0.3998357057571411),\n",
       " ('империя_NOUN', 0.3950481116771698),\n",
       " ('акихито_PROPN', 0.3925309181213379),\n",
       " ('мария::федоровна_PROPN', 0.38869190216064453),\n",
       " ('анна::иоанновна_PROPN', 0.38844308257102966),\n",
       " ('вельможа_NOUN', 0.3760373592376709)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.most_similar(positive=[u'пожар_NOUN'])\n",
    "#model.most_similar(positive=[u'пожар_NOUN', u'пламя_NOUN' ])\n",
    "#model.most_similar(positive=[u'пожар_NOUN', u'пламя_NOUN' ], negative=[u'топливо_NOUN'])\n",
    "model.most_similar(positive=[u'женщина_NOUN', u'император_NOUN' ], negative=[u'мужчина_NOUN'])\n",
    "#model.most_similar(positive=[u'женщина_NOUN', u'король_NOUN' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
